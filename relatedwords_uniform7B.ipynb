{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jxpETIV5rih"
      },
      "source": [
        "**DeepSeek-R1-Distill-Qwen-7B**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "utp50q_f5uAk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def frobenius_distance(A, B):\n",
        "    # Returns the Euclidean distance between two matrices\n",
        "    return torch.linalg.matrix_norm(A - B, ord='fro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "c239b566c46e4a0493ebbf0cd363f976",
            "a865c8b5b46f4f21a6cbb9a59dcd7e2b",
            "b2ad7e4de492456ca0c526e436365fd7",
            "80a8afcda8d3460ab3c0d54c9245288b",
            "da24a27eb8b34d44ae206047b43af4ab",
            "cdde7c3af1564b799a967227502ab69f",
            "6eea40e1b9fa4759b94a12e067f8bfb2",
            "f7e847eabc99496192f43d6a5224a00e",
            "2d2d750e733446cd8ee25b0ded630488",
            "27657a44a0bf45de89195607241d5252",
            "5cd884b94d85498bac22e48bf1ab86d7"
          ]
        },
        "id": "CDmXJrue56dK",
        "outputId": "67470cb1-1cfc-48a8-e823-2dd820895738"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c239b566c46e4a0493ebbf0cd363f976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix Shape:   torch.Size([152064, 3584])\n",
            "Unembedding matrix Shape: torch.Size([152064, 3584])\n",
            "- The matrices have the SAME shape (not transposed).\n",
            "- Weights are UNTIED and distinct.\n",
            "DeepSeek-R1-Distill-Qwen-7B Config 'tie_word_embeddings':     False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
        "\n",
        "#should try other maybe larger models\n",
        "tokenizer_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "model_name = tokenizer_name\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# extract embedding\n",
        "embeddings = model.model.embed_tokens.weight\n",
        "\n",
        "# extract unembedding\n",
        "unembedding = model.lm_head.weight\n",
        "\n",
        "print(f\"Embedding matrix Shape:   {embeddings.shape}\")\n",
        "print(f\"Unembedding matrix Shape: {unembedding.shape}\")\n",
        "\n",
        "#comparing the embedding matrix and the unembedding matrix\n",
        "if embeddings.shape == unembedding.t().shape:\n",
        "    print(\"- The matrices have transposed shapes.\")\n",
        "elif embeddings.shape == unembedding.shape:\n",
        "    print(\"- The matrices have the SAME shape (not transposed).\")\n",
        "else:\n",
        "    print(\"- The matrices have different shapes.\")\n",
        "\n",
        "if embeddings is unembedding:\n",
        "    print(\"- Weights are TIED (Same object in memory).\")\n",
        "elif torch.allclose(embeddings, unembedding, atol=1e-5):\n",
        "    print(\"- Weights are distinct objects but are the exact same.\")\n",
        "else:\n",
        "    print(\"- Weights are UNTIED and distinct.\")\n",
        "\n",
        "print(f\"DeepSeek-R1-Distill-Qwen-7B Config 'tie_word_embeddings':     {model.config.tie_word_embeddings}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWnV65kT6Mig",
        "outputId": "0435f54c-94f7-43d3-a469-b01befe01a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The frobenius distance from the embedding to the unembedding matrix of DeepSeek-R1-Distill-Qwen-7B is 534.2822875976562.\n",
            "The relative frobenius distance from the embedding to the unembedding matrix of DeepSeek-R1-Distill-Qwen-7B is 1.3745619058609009.\n"
          ]
        }
      ],
      "source": [
        "distance = frobenius_distance(embeddings, unembedding)\n",
        "print(f\"The frobenius distance from the embedding to the unembedding matrix of DeepSeek-R1-Distill-Qwen-7B is {distance}.\")\n",
        "\n",
        "emb_mat_norm = torch.linalg.matrix_norm(embeddings, ord='fro')\n",
        "rel_distance = distance/emb_mat_norm\n",
        "\n",
        "print(f\"The relative frobenius distance from the embedding to the unembedding matrix of DeepSeek-R1-Distill-Qwen-7B is {rel_distance}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gi328f-ENQ",
        "outputId": "eb9800e5-439a-4105-f4d0-088fad95f370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleModel(\n",
              "  (embedding): Embedding(152064, 3584)\n",
              "  (unembedding): Linear(in_features=3584, out_features=152064, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ALWAYS RUN THIS CELL FIRST\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer\n",
        "from load_embeddings import load_embedding_model\n",
        "from utils import find_similar_embeddings, prompt_to_embeddings, find_similar_logits, get_token_embedding, token_len_one_verifier, test_combinations\n",
        "\n",
        "model, tokenizer = load_embedding_model(152064, 3584, \"deepseek-ai_DeepSeek-R1-Distill-Qwen-7B_embeddings_qwen.pth\", \"deepseek-ai_DeepSeek-R1-Distill-Qwen-7B_unembeddings_qwen.pth\", \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aR40lGl1cfX"
      },
      "source": [
        "**Colors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9NQ3BGbOPl1",
        "outputId": "a4be1c8d-88dc-4706-e9e3-44db0fb6c5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown', 'black', 'white', 'gray', 'cyan', 'gold', 'silver', 'cream', 'tan', 'amber', 'azure', 'rose', 'ruby']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token colors\n",
        "colors = [\"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"purple\", \"pink\", \"brown\", \"black\", \"white\", \"gray\", \"cyan\", \"gold\", \"silver\", \"cream\", \"tan\", \"amber\", \"azure\", \"rose\", \"ruby\"]\n",
        "\n",
        "one_tok_colors = []\n",
        "for color in colors:\n",
        "    if token_len_one_verifier(tokenizer, color):\n",
        "        one_tok_colors.append(color)\n",
        "\n",
        "print(one_tok_colors)\n",
        "print(len(colors))\n",
        "print(len(one_tok_colors))\n",
        "\n",
        "#Getting the embeddings\n",
        "color_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_colors}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yav6n6XdORlt",
        "outputId": "3c89649c-7cc3-40e5-c148-34bb74055efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_colors, color_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6YSsiPj2AWz"
      },
      "source": [
        "**Animals**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy-juRRx2DkB",
        "outputId": "56274714-07ee-4b11-cdb4-31c884695af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cat', 'dog', 'lion', 'bear', 'wolf', 'fox', 'cow', 'pig', 'horse', 'deer', 'mouse', 'rat', 'rabbit', 'monkey', 'snake', 'frog', 'duck', 'hawk', 'fish', 'owl']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token animals\n",
        "animals = [\"cat\", \"dog\", \"lion\", \"bear\", \"wolf\", \"fox\", \"cow\", \"pig\", \"horse\", \"deer\", \"mouse\", \"rat\", \"rabbit\", \"monkey\", \"snake\", \"frog\", \"duck\", \"hawk\", \"fish\", \"owl\"]\n",
        "\n",
        "one_tok_animals = []\n",
        "for animal in animals:\n",
        "    if token_len_one_verifier(tokenizer, animal):\n",
        "        one_tok_animals.append(animal)\n",
        "\n",
        "print(one_tok_animals)\n",
        "print(len(animals))\n",
        "print(len(one_tok_animals))\n",
        "\n",
        "#Getting the embeddings\n",
        "animal_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_animals}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmbSfmck2O4N",
        "outputId": "e77e906d-0b3f-4f5d-9d8c-3aa7c555c3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_animals, animal_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87roN9z2Viy"
      },
      "source": [
        "**Common verbs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsDQM6rs2U3j",
        "outputId": "09905c34-3941-4ec5-ee39-176ed5e3cec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['run', 'walk', 'jump', 'sit', 'stand', 'sleep', 'eat', 'drink', 'read', 'write', 'open', 'close', 'listen', 'watch', 'play', 'move', 'stop', 'go', 'come', 'think']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token verbs\n",
        "verbs = [\"run\", \"walk\", \"jump\", \"sit\", \"stand\", \"sleep\", \"eat\", \"drink\", \"read\", \"write\",\n",
        " \"open\", \"close\", \"listen\", \"watch\", \"play\", \"move\", \"stop\", \"go\", \"come\",\n",
        " \"think\"]\n",
        "\n",
        "one_tok_verbs = []\n",
        "for verb in verbs:\n",
        "    if token_len_one_verifier(tokenizer, verb):\n",
        "        one_tok_verbs.append(verb)\n",
        "\n",
        "print(one_tok_verbs)\n",
        "print(len(verbs))\n",
        "print(len(one_tok_verbs))\n",
        "\n",
        "#Getting the embeddings\n",
        "verb_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_verbs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYZc7ppZ2ZfZ",
        "outputId": "27d79383-510f-489a-bc45-f1bc5f40e389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_verbs, verb_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xxa29362c8f"
      },
      "source": [
        "**Geometric object**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebN2uatr2fzz",
        "outputId": "9f87b016-8fd5-4b9c-8476-8ac4aafcb932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['circle', 'square', 'triangle', 'rectangle', 'oval', 'cube', 'cone', 'sphere', 'ellipse', 'line', 'curve', 'ring', 'dot', 'cross', 'loop', 'polygon', 'point', 'plane', 'edge', 'angle']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token geometry\n",
        "geo_objects = [\"circle\", \"square\", \"triangle\", \"rectangle\", \"oval\", \"cube\", \"cone\", \"sphere\", \"ellipse\", \"line\", \"curve\", \"ring\", \"dot\", \"cross\", \"loop\", \"polygon\", \"point\", \"plane\", \"edge\", \"angle\"]\n",
        "\n",
        "one_tok_geo_objects = []\n",
        "for geo_object in geo_objects:\n",
        "    if token_len_one_verifier(tokenizer, geo_object):\n",
        "        one_tok_geo_objects.append(geo_object)\n",
        "\n",
        "print(one_tok_geo_objects)\n",
        "print(len(geo_objects))\n",
        "print(len(one_tok_geo_objects))\n",
        "\n",
        "#Getting the embeddings\n",
        "geo_object_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_geo_objects}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EebnKezu2hh9",
        "outputId": "fdc69e59-de90-40a5-85ee-47cd4f63fa21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_geo_objects, geo_object_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe2phQd42jwq"
      },
      "source": [
        "**Body parts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SevXf7Dr2jW5",
        "outputId": "da37a78c-58ac-4672-f222-5a5c803ae84f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['head', 'hand', 'arm', 'leg', 'foot', 'eye', 'ear', 'mouth', 'back', 'neck', 'finger', 'chest', 'hip', 'hair', 'skin', 'face', 'throat', 'brain', 'heart', 'lung']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token body parts\n",
        "body_parts = [\"head\", \"hand\", \"arm\", \"leg\", \"foot\", \"eye\", \"ear\", \"mouth\", \"back\", \"neck\", \"finger\", \"chest\", \"hip\", \"hair\", \"skin\", \"face\", \"throat\", \"brain\", \"heart\", \"lung\"]\n",
        "one_tok_body_parts = []\n",
        "for body_part in body_parts:\n",
        "    if token_len_one_verifier(tokenizer, body_part):\n",
        "        one_tok_body_parts.append(body_part)\n",
        "\n",
        "print(one_tok_body_parts)\n",
        "print(len(body_parts))\n",
        "print(len(one_tok_body_parts))\n",
        "\n",
        "#Getting the embeddings\n",
        "body_part_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_body_parts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3xG2Rww2o4W",
        "outputId": "a90d8ee2-3af1-4da7-fed1-7258b8ed5516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.002\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.004\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.003\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.004\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.002\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.002\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.002\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_body_parts, body_part_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeWFMY5M2tlV"
      },
      "source": [
        "**Adjectives**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJuqOvTM2vu1",
        "outputId": "4876a4b2-bfdf-4574-c838-a562eaf294cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['good', 'bad', 'new', 'old', 'big', 'small', 'long', 'short', 'high', 'low', 'wide', 'deep', 'hot', 'cold', 'dark', 'light', 'soft', 'hard', 'fast', 'slow']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token adjectives\n",
        "adjectives = [\"good\", \"bad\", \"new\", \"old\", \"big\", \"small\", \"long\", \"short\", \"high\", \"low\", \"wide\", \"deep\", \"hot\", \"cold\", \"dark\", \"light\", \"soft\", \"hard\", \"fast\", \"slow\"]\n",
        "one_tok_adjectives = []\n",
        "for adjective in adjectives:\n",
        "    if token_len_one_verifier(tokenizer, adjective):\n",
        "        one_tok_adjectives.append(adjective)\n",
        "\n",
        "print(one_tok_adjectives)\n",
        "print(len(adjectives))\n",
        "print(len(one_tok_adjectives))\n",
        "\n",
        "#Getting the embeddings\n",
        "adjective_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_adjectives}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS92UPKJ2xP-",
        "outputId": "98b8b5de-5fbc-4919-f6af-e039a5376fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.010526315789473684\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.02000000000000001\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.023000000000000013\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.037000000000000026\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.028000000000000018\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.03300000000000002\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.03300000000000002\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.04200000000000003\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.04500000000000003\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.037000000000000026\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.05400000000000004\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.04000000000000003\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.02900000000000002\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.03200000000000002\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.016000000000000007\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_adjectives, adjective_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19FLC3UZ2z--"
      },
      "source": [
        "**Pronouns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYpx_Ozl22ET",
        "outputId": "23f60e90-9f59-4665-e70a-fac3711b41e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'mine', 'his', 'its', 'ours', 'this', 'that', 'these', 'those']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token pronouns\n",
        "pronouns = [\"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\", \"mine\", \"his\", \"its\", \"ours\", \"this\", \"that\", \"these\", \"those\"]\n",
        "\n",
        "one_tok_pronouns = []\n",
        "for pronoun in pronouns:\n",
        "    if token_len_one_verifier(tokenizer, pronoun):\n",
        "        one_tok_pronouns.append(pronoun)\n",
        "\n",
        "print(one_tok_pronouns)\n",
        "print(len(pronouns))\n",
        "print(len(one_tok_pronouns))\n",
        "\n",
        "#Getting the embeddings\n",
        "pronoun_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_pronouns}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exebyJBs23ny",
        "outputId": "33e1ef0c-6689-4955-b9b7-814a6b0d0c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.002\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_pronouns, pronoun_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FfRAzee26ms"
      },
      "source": [
        "**Prepositions & Conjunctions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUeLrMK33AXb",
        "outputId": "4a3446b9-b593-4c39-9129-1407c158f759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['of', 'in', 'on', 'at', 'to', 'for', 'from', 'with', 'by', 'up', 'down', 'out', 'over', 'and', 'or', 'but', 'so', 'if', 'than', 'as']\n",
            "20\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "#Getting one token prepositions & conjunctions\n",
        "p_cs = [\"of\", \"in\", \"on\", \"at\", \"to\", \"for\", \"from\", \"with\", \"by\", \"up\", \"down\", \"out\", \"over\", \"and\", \"or\", \"but\", \"so\", \"if\", \"than\", \"as\"]\n",
        "\n",
        "one_tok_p_cs = []\n",
        "for p_c in p_cs:\n",
        "    if token_len_one_verifier(tokenizer, p_c):\n",
        "        one_tok_p_cs.append(p_c)\n",
        "\n",
        "print(one_tok_p_cs)\n",
        "print(len(p_cs))\n",
        "print(len(one_tok_p_cs))\n",
        "\n",
        "#Getting the embeddings\n",
        "p_c_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_p_cs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuEqxgg03Bnp",
        "outputId": "f4199f75-bc55-4f8e-e66e-9b023d39a70d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_p_cs, p_c_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNI9RvLtZRpZ"
      },
      "source": [
        "**Random words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaQcHV8JZRCt",
        "outputId": "c8a0a3f9-6a3d-47ee-8ee8-f2c9fa4771e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cube', 'at', 'horse', 'he', 'green', 'dot', 'cream', 'them', 'cold', 'play', 'back', 'azure', 'come', 'good', 'hand', 'snake', 'yellow', 'fox', 'we', 'plane', 'gray', 'read', 'hot', 'amber', 'eat', 'walk', 'mine', 'than', 'ear', 'to']\n",
            "30\n",
            "30\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "#Getting one token prepositions & conjunctions\n",
        "alls = [\"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"purple\", \"pink\", \"brown\", \"black\", \"white\", \"gray\", \"cyan\", \"gold\",\n",
        "        \"silver\", \"cream\", \"tan\", \"amber\", \"azure\", \"rose\", \"ruby\", \"cat\", \"dog\", \"lion\", \"bear\", \"wolf\", \"fox\", \"cow\",\n",
        "        \"pig\", \"horse\", \"deer\", \"mouse\", \"rat\", \"rabbit\", \"monkey\", \"snake\", \"frog\", \"duck\", \"hawk\", \"fish\", \"owl\", \"run\",\n",
        "        \"walk\", \"jump\", \"sit\", \"stand\", \"sleep\", \"eat\", \"drink\", \"read\", \"write\", \"open\", \"close\", \"listen\", \"watch\", \"play\",\n",
        "        \"move\", \"stop\", \"go\", \"come\", \"think\", \"circle\", \"square\", \"triangle\", \"rectangle\", \"oval\", \"cube\", \"cone\", \"sphere\",\n",
        "        \"ellipse\", \"line\", \"curve\", \"ring\", \"dot\", \"cross\", \"loop\", \"polygon\", \"point\", \"plane\", \"edge\", \"angle\", \"head\", \"hand\",\n",
        "        \"arm\", \"leg\", \"foot\", \"eye\", \"ear\", \"mouth\", \"back\", \"neck\", \"finger\", \"chest\", \"hip\", \"hair\", \"skin\", \"face\", \"throat\",\n",
        "        \"brain\", \"heart\", \"lung\", \"good\", \"bad\", \"new\", \"old\", \"big\", \"small\", \"long\", \"short\", \"high\", \"low\", \"wide\", \"deep\",\n",
        "        \"hot\", \"cold\", \"dark\", \"light\", \"soft\", \"hard\", \"fast\", \"slow\", \"I\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\",\n",
        "        \"her\", \"us\", \"them\", \"mine\", \"his\", \"its\", \"ours\", \"this\", \"that\", \"these\", \"those\", \"of\", \"in\", \"on\", \"at\", \"to\", \"for\",\n",
        "        \"from\", \"with\", \"by\", \"up\", \"down\", \"out\", \"over\", \"and\", \"or\", \"but\", \"so\", \"if\", \"than\", \"as\"]\n",
        "\n",
        "alls = sorted(alls)\n",
        "alls = random.sample(alls, 30)\n",
        "\n",
        "one_tok_alls = []\n",
        "for all in alls:\n",
        "    if token_len_one_verifier(tokenizer, all):\n",
        "        one_tok_alls.append(all)\n",
        "\n",
        "print(one_tok_alls)\n",
        "print(len(alls))\n",
        "print(len(one_tok_alls))\n",
        "\n",
        "#Getting the embeddings\n",
        "all_embeddings = {c: get_token_embedding(model, tokenizer, c) for c in one_tok_alls}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9by6T61ZYNf",
        "outputId": "dcfec1fe-e634-4d93-81d5-ee0f58d78795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combination size: 1\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 2\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 3\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 4\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 5\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 6\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 7\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 8\n",
            "0.001\n",
            "\n",
            "\n",
            "Combination size: 9\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 10\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 11\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 12\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 13\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 14\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 15\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 16\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 17\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 18\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 19\n",
            "0.0\n",
            "\n",
            "\n",
            "Combination size: 20\n",
            "0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Testing combinations of different sizes from 1 to 20\n",
        "combination_sizes = list(range(1, 21))\n",
        "results = test_combinations(model, tokenizer, one_tok_alls, all_embeddings, combination_sizes, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-DkF_60WMda",
        "outputId": "f441850c-d6fd-4104-a41e-c1de8dbd4de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('red', 1.0000008344650269), (' red', 0.3085389733314514), ('RED', 0.26520079374313354), ('Red', 0.2539021372795105), (' Red', 0.24568769335746765), ('re', 0.21863503754138947), ('.red', 0.21691332757472992), ('红', 0.21409417688846588), ('res', 0.20547159016132355), ('reds', 0.19922350347042084), ('(red', 0.1967708170413971), ('med', 0.19023369252681732), ('blue', 0.1826041340827942), ('black', 0.1825292408466339), ('_red', 0.1798408478498459), (' pred', 0.17737917602062225), ('rel', 0.17565950751304626), ('led', 0.174979105591774), ('cred', 0.17025920748710632), ('ored', 0.16839295625686646)]\n"
          ]
        }
      ],
      "source": [
        "from utils import find_similar_embeddings, prompt_to_embeddings, find_similar_logits, get_token_embedding\n",
        "\n",
        "embedding = get_token_embedding(model, tokenizer, \"red\")\n",
        "similar = find_similar_embeddings(model, tokenizer, embedding, n = 20)\n",
        "print(similar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdM3dV4IWurA",
        "outputId": "85fd145b-4269-447b-f966-1e680620abf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " communicated    0.0619\n",
            " brew            0.0611\n",
            " Rich            0.0582\n",
            " threaded        0.0577\n",
            " Anthrop         0.0570\n",
            "unts             0.0556\n",
            "pro              0.0552\n",
            "(\".              0.0551\n",
            "Monster          0.0535\n",
            "acy              0.0531\n",
            " caster          0.0531\n",
            "_running         0.0528\n",
            "Mut              0.0527\n",
            " mistaken        0.0520\n",
            " dens            0.0517\n",
            " basically       0.0515\n",
            "海拔               0.0515\n",
            "不合理              0.0514\n",
            "staff            0.0513\n",
            " Sylv            0.0511\n"
          ]
        }
      ],
      "source": [
        "grape = get_token_embedding(model, tokenizer, \"grape\")\n",
        "orange = get_token_embedding(model, tokenizer, \"orange\")\n",
        "apple = get_token_embedding(model, tokenizer, \"apple\")\n",
        "\n",
        "weighted_embedding_fruit = 0.33*grape + 0.33*orange + 0.34*apple\n",
        "top_words = find_similar_logits(model, tokenizer, weighted_embedding_fruit, n=20)\n",
        "\n",
        "for w, s in top_words:\n",
        "    print(f\"{w:15s}  {s:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27657a44a0bf45de89195607241d5252": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2d750e733446cd8ee25b0ded630488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cd884b94d85498bac22e48bf1ab86d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eea40e1b9fa4759b94a12e067f8bfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a8afcda8d3460ab3c0d54c9245288b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27657a44a0bf45de89195607241d5252",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd884b94d85498bac22e48bf1ab86d7",
            "value": " 2/2 [00:55&lt;00:00, 26.63s/it]"
          }
        },
        "a865c8b5b46f4f21a6cbb9a59dcd7e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdde7c3af1564b799a967227502ab69f",
            "placeholder": "​",
            "style": "IPY_MODEL_6eea40e1b9fa4759b94a12e067f8bfb2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b2ad7e4de492456ca0c526e436365fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e847eabc99496192f43d6a5224a00e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d2d750e733446cd8ee25b0ded630488",
            "value": 2
          }
        },
        "c239b566c46e4a0493ebbf0cd363f976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a865c8b5b46f4f21a6cbb9a59dcd7e2b",
              "IPY_MODEL_b2ad7e4de492456ca0c526e436365fd7",
              "IPY_MODEL_80a8afcda8d3460ab3c0d54c9245288b"
            ],
            "layout": "IPY_MODEL_da24a27eb8b34d44ae206047b43af4ab"
          }
        },
        "cdde7c3af1564b799a967227502ab69f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da24a27eb8b34d44ae206047b43af4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e847eabc99496192f43d6a5224a00e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
